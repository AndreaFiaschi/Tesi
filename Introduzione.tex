\chapter{Introduzione}

\section{Modello Standard}

{\bf MA TUTTO QUESTO PIPPONE SUL MS SERVE??????}

Il {\em Modello Standard} (MS) è la teoria che ad oggi descrive meglio la fenomenologia delle interazioni tra particelle elementari. Questa teoria, formulata nella seconda metà del novecento riesce a descrivere tre delle quattro interazioni fondamentali: interazione elettromagnetica, interazione debole e interazione forte, mentre ad oggi non esiste una estensione della teoria che comprenda l'interazione gravitazionale.

\begin{figure}
\centering
\includegraphics[scale=0.3]{Immagini/SM}
\caption{Particelle elementari del Modello Standard.}
\label{fig:SM}
\end{figure}

Il Modello Standard descrive la materia come composta da due tipi di particelle, entrambi fermioni con spin $\nicefrac{1}{2}$, {\em leptoni} e {\em quark}:

\begin{itemize}
\item i {\em leptoni} hanno carica elettrica intera e quelli conosciuti sono sei, suddivisi in tre generazioni di doppietti con massa crescente. Ogni doppietto è costituito da una particella con carica $Q=-1$ che ha interazioni elettrodeboli, rispettivamente l'elettrone $e$, il muone $\mu$ e il leptone tau $\tau$ nelle tre generazioni. Il doppietto \`e completato da una particella neutra chiamata {\em neutrino}, $\nu_e$, $\nu_{\mu}$ e $\nu_{\tau}$ rispettivamente, che interagisce solo per interazione debole.
\item Analogamente ai leptoni i {\em quark} sono organizzati in doppietti. In questo caso però la carica è frazionaria: la componente superiore del doppietto ha carica $Q=2/3$ ed \`e costituita dai quark $u$, $c$ e $t$ rispettivamente per le tre generazioni. La componente inferiore ha carica $Q=-1/3$ ed \`e costituita dai quark $d$, $s$ e $b$ rispettivamente per le tre generazioni. I quark interagiscono sia elettrodebole che forte e quest'ultima interazione è alla base della formazione di stati legati chiamati adroni, come ad esempio neutrone e protone.
\end{itemize}

Ad ognuna di queste particelle corrisponde una antiparticella che ha i numeri quantici opposti ma stessa massa e spin. Oltre alle antiparticelle il Modello Standard prevede l'esistenza dei {\em bosoni di gauge} e del {\em bosone di Higgs}. I primi sono i mediatori delle interazioni che, a loro volta, derivano dalle simmetrie insite nella teoria:

\begin{itemize}
\item il {\em fotone} \`e responsabile della mediazione dell'interazione elettromagnetica;
\item i {\em bosoni $W^{\pm}$} e $Z$, sono i mediatori dell'interazione debole; un'esempio in cui entra in gioco questa forza è il decadimento $\beta$. Questi bosoni, sono massivi, circa $80\GeVcc$ e $91\GeVcc$ rispettivamente.
\item I {\em gluoni} sono i mediatori dell'interazione forte.
\end{itemize}

Come detto precedentemente la forza gravitazionale non è descritta dal MS, ma risulta essere trascurabile nelle interazione tra particelle, in quanto la sua intensità, paragonata a quella delle altre tre forze, è vari ordini di grandezza inferiore. Nel MS le interazioni sono descritte come manifestazioni di simmetrie di gauge della Lagrangiana. Queste simmetrie non ammettono termini di massa per i bosoni di gauge poiché questo porterebbe alla rottura delle simmetrie stesse. Tuttavia \`e possibile introdurre un meccanismo di rottura spontanea della simmetria, detto {\em di Higgs}, da cui derivano i termini di massa per i bosoni di gauge e un ulteriore bosone scalare massivo, il {\em bosone di Higgs}. Attraverso il meccanismo di Higgs vengono anche introdotti i termini di massa dei fermioni.

{\bf Aggiungere un paragrafetto sulle problematiche del MS (dark matter, teoria efficace a bassa energia etc.). Per questo si costruiscono gli acceleratori ...}

\section{LHC e l'esperimento CMS}
Il {\em Large Hadron Collider} o {\em LHC} è attualmente il più grande acceleratore di particelle mai costruito. Si trova presso il {\em CERN} ({\em European Organization for Nuclear Research}), collocato in un anello sotterraneo di 27~km nella regione di Ginevra (Svizzera). 

LHC \`e un collider adronico in grado di produrre interazioni protone-protone all'energia di $13\TeV$ nel centro di massa. \`E stato progettato con due anelli separati con campo magnetico opposto in modo che i fasci controrotanti possano essere costituiti da particelle con la stessa carica elettrica. Questa caratteristica, oltre ad altre, fa di LHC una macchina di frontiera di ineguagliata complessit\`a che ha richiesto una grande innovazione tecnologica. 

L'accelerazione dei protoni avviene a stadi come schematizzato in~Fig.~\ref{fig:LHC}: i protoni ottenuti da idrogeno gassoso sono inizialmente accelerati da un acceleratore lineare, LINAC2. Successvamente i protoni sono iniettati nel Proton Synchroton Booster (PSB) che aumenta l'energia fino a $1.4\GeV$ e, in seguito, grazie al Proton Synchrotron, raggiungono i $25\GeV$. In queste fasi i protoni vengono raggruppati in pacchetti distanti temporalmente $25\ns$ intervallo che che corrisponde alla frequenza di interazioni di $40\MHz$ a cui LHC opera. 
I protoni vengono infine accelerati fino ad energie di $450\GeV$ nel Super Proton Synchrotron (SPS) prima di essere iniettati nei due anelli di LHC in cui subiscono l'ultima fase di accelerazione fino all'energia di $13\TeV$ prima di farli collidere nei punti in cui sono collocati gli esperimenti.

Il {\em Compact Muon Solenoid} o {\em CMS} è uno dei principali esperimenti di LHC, assieme ad ALICE, ATLAS e LHCb. 

\begin{figure}
\centering
\includegraphics[scale=0.25]{Immagini/LHC}
\caption{Schema di pre-accelerazione e accelerazione di LHC.}
\label{fig:LHC}
\end{figure}

Lo scopo di questi esperimenti è lo studio del MS e la ricerca della materia oscura e di evidenze di nuova fisica, ovvero fenomeni non previsti dal MS stesso. Questi esperimenti sono collocati nei punti in cui i fasci di particelle si incrociano e le interazioni protone-protone prodotte possono essere quindi registrate ed essere analizzate in seguito. Pi\`u nel dettaglio:
\begin{itemize}
\item ALICE (A Large Ion Collider Experiment) \`e un esperimento che studia un stato della materia noto come {\em quark-gluon plasma}, prodotto nelle collisioni di ioni pesanti dal momento che, oltre alle collisioni protone-protone, LHC pu\`o operare come collisionatore ione-ione;
\item CMS (Compact Muon Solenoid) e ATLAS (A Toroidal LHC ApparatuS) sono entrambi progettati con lo scopo di investigare il più ampio spettro di fisica possibile. I due esperimenti hanno gli stessi obbiettivi, ma sono stati costruiti in modo differente al fine di essere indipendenti nello studio dei processi di interazione che avvengono durante le collisioni tra due protoni. Atlas e CMS nel 2012 hanno scoperto il bosone di Higgs~\cite{scopertahiggs}. 
\item LHCb (LHC beauty) \`e un esperimento che studia la fisica degli adroni contenenti il quark b e la violazione di CP (coniugazione di Carica e Parità) nelle interazioni elettrodeboli.
\end{itemize}
Altri esperimenti presenti ad LHC, ma di dimensioni minori sono TOTEM e LHCf:
\begin{itemize}
\item TOTEM (TOTal Elastic and diffractive cross section Measurement), ha come fine lo studio della fisica diffrettiva a piccolo angolo nelle interazioni protone-protone;
\item LHCf (LHC forward) è composto da due rivelatori che sono posizionati a $140$m dal punto di collisione di ATLAS per lo studio delle interazioni calorimetriche dei pioni neutri a grande rapidità e altissima energia, con lo scopo di verificare i modelli di simulazione per meglio modellizzare il comportamento dei raggi cosmici primari nell'interazione con l'atmosfera.
\end{itemize}

In un acceleratore due sono i parametri operativi fondamentali che ne determinano il potenziale di scoperta e la capacit\`a di effettuare accurate misure di fisica: l'energia del centro di massa e la luminosit\`a.

Pi\`u grande l'energia nel centro di massa, maggiore la massa delle particelle che possono essere prodotte e, in generale, a parit\`a di massa, \`e maggiore la sezione d'urto di produzione e quindi il numero di potenziali osservazioni. L'energia nel centro di massa di LHC \`e attualmente $\sqrt{s}=13\TeV$ a cui si \`e arrivati gradualmente: durante il RunI (2010-2012) l'energia del centro di massa \`e stata compresa tra 7 e $8\TeV$ ed \`e stata incrementata al valore attuale per il RunII (2015-2018).  

La struttura non elementare dei protoni, costituiti internamente da partoni (quark e gluoni) che si dividono l'impulso totale, permette di produrre stati di energia intermedia fino al limite cinematico dell'energia del centro di massa e quindi di esplorare un ampio intervallo di energie senza dover modificare i parametri di funzionamento dell'acceleratore. Nella collisione l'interazione effettiva coinvolge solo una coppia di partoni che trasportano una frazione dell'impulso nominale dei due protoni. Questo costituisce un grande vantaggio dei collider adronici rispetto ai collider $\ee$ nell'ambito delle analisi di fisica di scoperta.

%che aumenta la probabilit\`a di produrre  motivo di una così alta energia è spiegato con la necessità di indagare processi fisici i cui effetti sono %maggiormente visibili se si è sopra una certa scala di energia. Un esempio è il Bosone di Higgs scoperto nel 2012, la cui massa è circa $125$ $GeV$.

Un ingrediente fondamentale per raggiungere energie elevate \`e il campo magnetico in cui sono immersi i tubi in cui circolano i fasci che sono inoltre tenuti ad una pressione di vuoto è di $10^{-13}{\mathrm atm}$, per evitare che i protoni interagiscano con le molecole di gas. Il campo magnetico, ortogonale al piano dell'anello, permette ai fasci di rimanere su una traiettoria quasi circolare. In particolare:
\begin{equation}
P[\GeVc] \sim 0.3 \cdot B[{\mathrm T}] \cdot r[\m]
\end{equation}
dove $B$ è il campo magnetico, $r$ il raggio di curvatura e $P$ l'impulso della particella. Dati i parametri di LHC ($r\sim4 \cdot 10^3\m$ e $P=6.5\TeVc$) si ottiene un campo $B$ che in media è pari a $\sim 5.4{\mathrm T}$. Per ottenere un campo di tale intensit\`a è stato necessario sviluppare dipoli magnetici superconduttori, il che ha rappresentato un'importante sfida tecnologica per la progettazione di LHC. Gran parte dell'anello di LHC, infatti, \`e mantentunto a temperature criogeniche di $\sim 2\degrees {\mathrm K}$ grazie ad un complesso sistema di raffreddamento.

{\bf correggere definizione luminosit\`a}

La {\em luminosit\`a} \`e proporzionale al numero di interazioni che l'acceleratore pu\`o fornire agli esperimenti ed \`e una grandezza fondamentale per stimare la capacit\`a dell'acceleratore di produrre eventi con piccola sezione d'urto e, quindi, la possibilit\`a degli esperimenti di osservarli. Al fine di ottenere risultati con un'ampia statistica ed una buona precisione è importante per un acceleratore avere una alta luminosità istantanea, un parametro che corrisponde al numero di collisioni prodotte per unità di area e tempo e può essere espressa in funzione del rate R di particelle {\bf(che cazzo vor di'?????)} e della sezione d'urto $\sigma$ 
\begin{equation}
L=\frac{R}{\sigma}
\end{equation}
Un altro modo di esprimere la luminosità è metterla in funzione delle variabili che caratterizzano il fascio:
\begin{equation}
L = f \frac{N_1 N_2}{4 \pi \sigma_x \sigma_y}
\end{equation}
con $N_1$ $N_2$ numerodi protoni per pacchetto, $f$ frequenza collisioni e $4\pi \sigma_x \sigma_y =A$ area efficace. Si parla invece di {\em luminosità integrata} $L_{int}=\int L dt$ per ottenere la relazione tra numero di eventi relativi a un certo processo e la sezione d'urto $\sigma$ del processo stesso:
\begin{equation}
N=\sigma L_{int}.
\end{equation}

\section{HL-LHC}
Il progetto di upgrade HL-LHC, formalmente approvato nel Giugno 2016 dal CERN, permetter\`a di ampliare il campo di indagine di fenomeni fisici rari all'interno del MS ed anche di ricercare processi di nuova fisica BSM (Beyond Standard Model). Questa fase di alta luminosità permetterà a CMS di raggiungere precisioni dell'ordine del per cento sulle misure di accoppiamento del bosone di Higgs e la prima osservazione diretta di vertici trilineari del bosone di Higgs. 
I processi deboli di scattering di bosoni vettori sono profondamente legati alla rottura della simmetria elettro bedole e dal punto di vista della misura sono una sfida, in quanto le sezioni d'urto sono piccole e i fondi irriducibili sono dominanti. 

L'aumento di luminosità ad LHC permetterà lo studio di questi canali, per far ciò  l'upgrade di LHC sarà accompagnato da un programma di adeguamento dell'esperimento CMS, al fine di mantenere alte le prestazioni del rivelatore (efficienza, risoluzione,reiezione di processi di fondo...) nonostante l'aumento di radiazione e le più difficili condizioni operative, come ad esempio pile-up più frequente.
In figura \ref{HL-LHC} è mostrato un prospetto della scaletta dei tempi di LHC dal 2015 in poi. Il Run 2 continuerà fino alla fine del 2018, quando inizierà il Long Shutdown 2 (LS2) e dopo cui si avrà la fase di Run 3.  Entro il 2022 si stima sarà raccolta una luminosità integrata di circa $300 fb^{-1}$. 
Durante il Long Shutdown 3 (LS3), programmata dal 2022 fino alla metà del 2024, saranno eseguiti gli aggiornamenti principali di LHC e degli esperimenti per la fase di alta luminosità.

\subsection{Obiettivi}
\begin{figure}
\centering
\includegraphics[scale=.35]{Immagini/HL-LHC}
\caption{Projected LHC performance through 2035, showing preliminary dates for long shut downs of LHC and projected luminosities.reference LHCC P 008}
\label{HL-LHC}
\end{figure}

L'idea di aumentare la luminosità di LHC oltre quella decisa nel progetto originale è antecedente alla messa in opera del progetto. Eventuali modifiche importanti alla macchina e agli esperimenti possono essere eseguite solo con lunghi periodi di shut down in cui è possibile accedere al tunnel e alle caverne. Per questo motivo è stato deciso un piano temporale che intervalli periodi di presa dati (Run I, Run II etc.) e periodi in cui si ha uno spegnimento completo per lunghi periodi (LS1, LS2, LS3). In figura \ref{HL-LHC} è possibile vedere la suddivisione temporale tra periodi di presa dati e periodi di spegnimento.
Run I è stato il periodo di presa dati dal 2011 al 2012. Nel primo periodo di stop LS1 LHC è stato modificato al fine di raggiungere energie  nel centro di massa di 13 TeV, per poi arrivare gradualmente a 14 TeV. In questo momento siamo alla fine del Run II, e nell'esperimento CMS si  hanno una media di 25 interazioni per bunch, ciò vuol dire 25 vertici da ricostruire ogni 25 ns. Attraverso modifiche  e miglioramenti apportati nel LS1 e LS2 verrà aumentata la luminosità, questa parte del processo per l'esperimento CMS va sotto il nome di fase-I. Durante il periodo LS3  saranno invece sostituite vari parti degli esperimenti, che a causa del danneggiamento da radiazione saranno deteriorati e nello contemporaneamente verranno sostituiti i quadrupoli di fuocheggiamento con nuovi modelli capaci di incrementare la luminosità. 
Il periodo che seguirà LS3 sarà chiamato fase II o HL-LHC (High Luminosity LHC). Nello scenario prefissato la lumiosità istantanea sarà di $5 \cdot 10 34 cm^{-2} s^{-1}$ con picchi di $2 \cdot 10 35 cm^{-2} s^{-1}$, in questo modo gli esperimenti saranno in grado di raccogliere una maggiore statistica con una luminosità di $300 fb^{-1}$ ogni anno per 10 anni(250 o 300)?????%at 5 × 10 34 cm − 2 s − 1 from a potential peak value of 2 × 10 35 cm − 2 s − 1 at the beginning of fills,
%and to deliver 250 fb − 1 per year for a further 10 years of operation. Under these conditions
In queste condizioni ci sarà una maggiore probabilità di sovrapposizione di interazioni (Pile Up), questa sarà la grande sfida, insieme alla gestione degli effetti di degradazione in cui incorreranno i rivelatori a seguito delle maggiori dosi di radiazione assorbita. Sempre nella figura \ref{HL-LHC} è possibile vedere le proiezioni di luminosità di picco e luminosità integrata.
 
%The high luminosity period that follows LS3 with the upgraded LHC is referred to here as HL-LHC or Phase-II. The proposed operating scenario is to level the instantaneous luminosity
%at 5 × 10 34 cm − 2 s − 1 from a potential peak value of 2 × 10 35 cm − 2 s − 1 at the beginning of fills,
%and to deliver 250 fb − 1 per year for a further 10 years of operation. Under these conditions the event PU will rise substantially to become a major challenge for the experiments, and the performance degradation due to integrated radiation dose will need to be addressed. This Technical Proposal presents the CMS upgrade program for Phase-II. The schedule of beam operations and long shutdowns, together with projections of the peak and integrated luminosities, is shown in Fig. 1.9, and is, of course, subject to change.

\section{Esperimento CMS}
CMS è un esperimento ad ampio spettro che opera ad LHC, è installato un centinaio di metri sotto terra CMS nei pressi del paese Cessy, in Francia, tra il lago di Ginevra e il complesso dei monti Jura. Essendo ad ampio spettro i suoi rivelatori sono in grado di distinguere un gran numero di particelle $e$, $\mu$, $\tau$, $\gamma$ etc...
L'obiettivo principe di LHC è quella di indagare la natura della rottura spontanea della simmetria elettrodebole alla base di cui sta il meccanismo di Higgs. Lo studio sperimentale del meccanismo di Higgs consente inoltre di verificare la consistenza del Modello Standard a scale di energia dei TeV. Inoltre c'è la speranza di nuove scoperte che offrano indicazioni su teorie oltre al Modello Standard, come ad esempio Supersimmetrie o Extra Dimension.
Ad LHC vengono utilizzati anche fasci di ioni pesanti, che hanno energie 30 volte superiori ai precedenti acceleratori, permettendo così uno studio approfondito della QCD in condizioni estreme di temperatura, densità e frazioni di momento partonico. Con la luminosità ed energia nel centro di massa raggiungibili ad LHC un ampio spettro di fisica diventa accessibile, questo però vincola i vari esperimenti, compreso CMS a richieste stringenti sulle prestazioni e quindi sulla progettazione e messa in opera.
Con un'energia nel centro di massa di 14 TeV la sezione d'urto protone-protone è circa 100 mb, data la  luminosità questo porta a circa $10^9$ eventi al secondo, che grazie al processo di selezione online viene abbassato fino a 100 eventi al secondo, i quali vengono poi memorizzati per una successiva analisi. 
Ogni 25 ns vi è una nuova collisione tra bunch di particelle che con le sue circa 20 collisioni produce un alto numero di particelle che dovranno essere rivelate con l'attenzione a distinguerle le une dalle altre. Questo richiede un'alta segmentazione del rivelatore e una buona risoluzione temporale , al fine di evitare effetti di pile-up. Il tutto cercando di ridurre il più possibile i volumi.
Inoltre dato l'alto flusso di particelle il rivelatore e l'elettronica di lettura devono essere in grado di resistere ad alti livelli di radiazione. Tutti questi motivi hanno  portato alla necessità di alti requisiti per il buon funzionamento dell'esperimento:
\begin{itemize}
\item Buona capacità di identificare i muoni e ottima risoluzione degli impulsi su ampio angolo.
\item Alta efficienza del tracciatore e buona risoluzione dei momenti di particelle cariche.
\item Buona risoluzione nella misura dell'energia elettromagnetica, copertura maggiore possibile di tutto l'angolo solido e ottima capacità di isolamento di fotoni e leptoni.
\item Buona risoluzione dell'energia trasversa mancante (MET) e calorimetri adronici con coperture ampia dell'angolo solido e buona segmentazione.
\end{itemize}

Il sistema di coordinate adottato da CMS è tale che l'origine corrisponde al punto di collisione dei due fasci con asse y verticale orientato verso l'alto e asse x in direzione radiale verso il centro di LHC. L'angolo azimutale $\phi$ è misurato a partire dall'asse x e giace sul piano x-y e la coordinata radiale su questo piano è $r$. L'angolo polare $\theta$ è misurato dall'asse z. 

Per lo studio dei processi è utile introdurre anche grandezze invarianti per trasformazioni di Lorentz come $\Delta y$ e $\Delta \eta$, dove y indica la rapidità e $\eta$ la pseudorapidità:
\begin{equation}
y= \dfrac{1}{2} ln\Big( \dfrac{E+p_z}{E-p_z}\Big)
\end{equation}

\begin{equation}
\eta = - ln \Big( tg\frac{\theta}{2}\Big)
\end{equation}
Infine la differenza nel bilancio dell'energia misurata sul piano trasverso è indicata come $E_T^{miss}$.


\subsection{Il rivelatore CMS}
CMS è un esperimento a simmetria cilindrica, ha un diametro di 15 m ed è lungo 21.6 m, per un peso complessivo di circa 12500 tonnellate. Lo scopo dell'esperimento è studiare una vasta gamma di processi fisici delle interazioni protone-protone, figura \ref{CMS}. 
\begin{figure}
\centering
\includegraphics[scale=.2]{Immagini/CMS}
\caption{Vista frontale di CMS durante l'installazione del tracciatore.}
\label{CMS}
\end{figure}
Per questo motivo è composto da diversi tipi di rivelatori, vedi figura \ref{CMSbis}, disposti in modo concentrico rispetto al punto di collisione dei due fasci:
\begin{itemize}
\item \textbf{Tracciatore}: collocato nella parte più interna è in grado di ricostruire la traiettoria delle particelle cariche  nella zona r $< 1.2$ m e $\mid\eta\mid$ $< 2.5$ individuando anche
eventuali vertici secondari. È suddiviso in due sottorivelatori: un rivelatore di vertice a pixel di silicio e un rivelatore a microstrip di silicio.

\item \textbf{Calorimetro elettromagnetico} (ECAL): è un calorimetro omogeneo composto da cristalli di tungstato di piombo (PbW$\mathrm{O_4}$), collocato nella regione 1.2 m $<$ $\mid$r$\mid$ $< 1.8$ m ed $\mid\eta\mid < 3$ misura l'energia di elettroni e fotoni, oltre che la traiettoria.

\item \textbf{Calorimetro adronico} (HCAL): posto nella regione con 1.8 m $<$ $\mid$r$\mid$ $< 2.9$ m ed $\mid\eta\mid$ $<$ 5, fornisce informazioni sull’energia e traiettoria delle particelle
adroniche. Il calorimetro utilizza strati di ottone alternati a strati di scintillatore plastico ed è suddiviso in quattro parti: HB (Barrel Hadronic Calorimeter) e HE (Endcap Hadronic Calorimeter) situati all’interno del magnete nella zona del barrel e dell’endcap, HO (Outer Hadronic Calorimeter) situato all'esterno del magnete e il HF (Forward Hadronic Calorimeter) anch'esso esterno al magnete e posto nella regione in avanti.

\item \textbf{Magnete superconduttore solenoidale}: posto nella regione 2.9 m $<$ r $< 3.8$ m, genera un campo magnetico uniforme di 3.8 T lungo la direzione dei fasci. Ciò permette di curvare la traiettoria delle particelle cariche, specialmente dei muoni, consentendo così di misurarne l'impulso trasverso. Il flusso del campo magnetico si richiude su un giogo di
ferro con diametro circa 14 m e lunghezza 21.6 m. In questa zona è presente una campo residuo di 1.8 T in direzione opposta a quello interno.

\item \textbf{Camere a muoni}: sono poste tra i vari strati del giogo di ritorno del campo magnetico, nella regione 4 m $<$ r $<$ 7.4 m e $\mid\eta\mid$ $<$ 2.4 e come dice il nome hanno il compito di rivelare i muoni. Queste camere a muoni sono di tre tipi, camere a deriva (DT) nel barrel, camere a strisce catodiche (CSC) nelle regioni estreme che chiudono il rivelatore, dette endcap, e camere a piastra resistiva (RPC).

\end{itemize}
%La parte centrale di CMS è racchiusa in un solenoide superconduttivo lungo 13 metri e con un diametro di 6, capace di generare un campo di $3.8 T$, questo consente  di curvare abbastanza la traiettoria di tutte le particelle cariche e specialmente dei muoni, consentendo così di misurarne l'impulso trasverso. Il campo magnetico del solenoide si richiude su un giogo di ritorno in ferro, inframezzato al ferro del giogo sono posizionati i rivelatori di muoni. Ogni rivelatore di muoni consta di vari strati di Drift Tubes in allumnio (DT) sulla superficie cilindrica e cathode strip chamber (CSC) nelle regioni estreme che chiudono il rivelatore, dette endcap, a questi si aggiungono le resistive plate chamber (RPC). 
%Nella parte interna del magnete è contenuto il tracciatore e i calorimetri. Per quanto riguarda il tracciatore la parte più interna è composta da 3 piani di rivelatori a pixel in  silicio, più esternamente sono stati installati 10 piani di rivelatori a microstrip di silicio. 
%Sempre internamente al solenoide sono posti intorno al tracciatore i calorimetri elettomagnetici (ECAL) utilizza cristalli di tungstato di piombo ($PbWO_4$) con copertura in pseudorapidità fino a  $|\eta |< 3.0$. La luce di scintillazione viene letta a fotodiodi a valanga di silicio (APDs) e fototriodi a vuoto (VPTs) nelle regioni di endcup, dove il campo magnetico è basso. 
\begin{figure}
\centering
\includegraphics[scale=0.8]{Immagini/CMSbis}
\caption{Spaccato di CMS e risposta ai vari tipi di particella.}
\label{CMSbis}
\end{figure}

Questa struttura rispecchia la necessità di ricostruire con precisione gli eventi originati dalla collisione di particelle, che avvengono in rapida successione. CMS come anche gli altri esperimenti, può essere paragonato ad una gigantesca macchina fotografica che registra 40 milioni di foto al secondo (digitalizzando l'informazione di decine di milioni di sensori). 
La struttura a strati consente di avere rivelatori diversi in ogni strato, di cui i più interni sono meno densi, mentre i più esterni sono più densi. Questo perché il tracciatore non deve alterare l'energia delle particelle che poi sarà misurata nei calorimetri e per facilitare la ricostruzione delle tracce è importante evitare fenomeni di multiple scattering.

Le particelle che gli scienziati cercano di riprodurre nelle collisioni protone-protone hanno vite medie molto brevi, e decadono rapidamente in particelle più leggere. Dopo un processo di hard-scattering migliaia di queste particelle leggere sono generate elettroni, muoni, fotoni, ma anche protoni, neutroni etc. Tutte queste particelle attraversano i vari strati di cui è composto il rivelatore. 
Le informazioni raccolte vengono utilizzate per ricostruire l'evento di interazione, per  dedurre l'esistenza di nuove particelle.


Le traiettorie delle particelle cariche sono piegate dal campo magnetico, e il loro raggio di curvatura è utilizzata per calcolare il loro impulso: maggiore è la loro energia cinetica, minore è la curvatura. Un'altra componente importante di un rivelatore sono i calorimetri per misurare l'energia delle particelle (sia cariche che non). 
I calorimetri devono essere abbastanza grandi per assorbire anche le particelle più energetiche. Questi motivi fanno sì che gli esperimenti ad LHC siano così grandi. I rivelatori sono costruiti in modo il più possibile ermetico per raccogliere tutti i prodotti delle interazioni e poter ricostruire gli eventi. 
Combinando le informazioni di ogni strato del rivelatore è possibile determinare il tipo di particella che ha lasciato una data traccia.

Particelle cariche come elettroni, protoni e muoni, lasciano tracce ionizzando il materiale attraversato. Gli elettroni sono molto leggeri e perciò perdono energia velocemente, mentre i protoni penetrano più in profondità negli strati del rivelatore. I fotoni essendo neutri non rilasciano segnali nel tracciatore, ma nei calorimetri sono convertiti in elettroni e positroni e così ne viene misurata l'energia. 
L'energia dei neutroni viene invece misurata indirettamente, trasferiscono l'energia ai protoni, che poi sono misurati. I muoni insieme ai neutrini (che non vengono rivelati) sono i soli a raggiungere gli strati più esterni.


\begin{figure}
\centering
\includegraphics[scale=0.7]{Immagini/CMSinterazione}
\caption{Spaccato di CMS e risposta ai vari tipi di particella.}
\label{CMSinterazione}
\end{figure}

Ogni parte del rivelatore è connessa ad un sistema di lettura elettronico attraverso migliaia di cavi. Ogni volta che un segnale è raccolto, il sistema registra la sua posizione e l'istante in cui è stato raccolto, se il sistema di trigger decide che l'evento che ha generato Se tale segnale è di interesse, allora l'informazione è letta e portata all'esterno del rivelatore per essere utilizzata nelle analisi offline.
Ci sono differenti criteri per selezionare un evento potenzialmente di interesse, in questo modo la mole enorme di eventi registrati in un secondo viene ridotta a poche centinaia, che poi verranno analizzate in dettaglio.


\subsection{Tracciatore}
Il tracciatore al silicio  è il rivelatore più vicino al punto dove collidono i due fasci. 
\begin{figure}
\centering
\includegraphics[scale=0.4]{Immagini/CMStracker2}
\caption{Schema di un quarto del tracciatore di CMS visto nel piano $rz$. Il rivelatore a pixel è rappresentato in verde, mentre i moduli a strip singoli e doppi sono in rispettivamente in rosso e blu.}
\label{CMStracker}
\end{figure}
Lo scopo è ricostruire , con la maggior precisione possibile, le traiettorie delle particelle cariche, identificando vertici primari e secondari. La composizione interna del tracciatore è mostrata in figura \ref{CMStracker}. Il raggio esterno è circa 110 cm e la lunghezza totale circa 540 cm.

Nella zona centrale (barrel) e più interna vi è il rivelatore di vertice a pixel, con tre strati distanti 4, 7 e 11 cm dall'asse dei fasci. La dimensione dei pixel è $100x150$ $\mu m^2$. Più esternamente ci sono rivelatori a microstrip tra 20 e 110 cm. Le parti laterali, dette endcap, sono invece costituite da 2 piani a pixel e 9 a microstrip. La parte di microstrip è divisa in due parti Inner Barrel e Outer Barrel, figura \ref{CMStracker}:
\begin{itemize}
\item Tracker Inner Barrel (TIB), costituito di 4 cilindri posti intorno ai piani a pixel.
\item Tracker Inner Discs (TID), 3 dischi posti nella parte interna di endcup.
\item Tracker Outer Barrel (TOB), 6 cilindri che formano la parte esterna del barrel.
\item Tracker EndCaps (TEC), 9 dischi che completano la parte più esterna di endcup.
\end{itemize}

%The Tracker will suffer significant radiation damage by LS3 and must be completely re-
%placed for Phase-II. To maintain adequate track reconstruction performance at the much higher
%PU pileup levels of the HL-LHC, the granularity of both the outer tracker and the pixel systems will
%be increased by roughly a factor 4. In the outer tracker, this will be achieved by shortening the
%lengths of silicon sensor strips relative to those in the current detector, without changing the
%pitch very significantly. A number of design improvements will lead to a much lighter Outer
%Tracker providing significantly improved p T resolution and a lower rate of γ-conversions com-
%pared to the present detector. In addition, the module design will be capable of providing track-stub information to the L1 trigger at 40 MHz for tracks with p T ≥ 2 GeV . This will en-
%sure powerful background rejection at the earliest stage of the event selection. The pixel system
%will implement smaller pixels and thinner sensors for improved impact parameter resolution
%and better two-track separation. This will improve b-tagging as well as τ-hadronic decay and
%track reconstruction efficiencies within boosted jets. With up to 10 additional pixel disks in
%each of the forward regions the system coverage will be extended to close to | η | = 4, to better
%match the range of coverage of the calorimetry.
\subsection{Tracciatore di fase II}

Al fine di mantenere o migliorare le prestazioni di CMS nelle condizioni di alto pile-up e alto danneggiamento da radiazioni, nella fase  di HL-LHC, l'intero sistema di tracciatura delle particelle dovrà essere sostituito con nuovi rivelatori capaci di sostenere livelli di radiazione maggiori e con maggiori funzionalità.
\begin{figure}
\centering
\includegraphics[scale=0.4]{Immagini/TrackerPhaseII}
\caption{Schema rappresentante un quarto del tracciatore. La parte esterna del tracciatore è in blu (moduli PS) e rosso (moduli 2S). La parte del tracciatore a pixel, con l'estensione in avanti è rappresentata in verde e giallo.}
\label{TrackerPhaseII}
\end{figure}

Le limitazioni dell'attuale tracciatore ne impediscono l'utilizzo nella fase di alta luminosità. I principali requisiti per il nuovo rivelatore sono i seguenti, figura \ref{TrackerPhaseII}:

\begin{itemize}
\item \textbf{Tolleranza alla radiazione}: Si prevede che il nuovo tracciatore dovrà operare, mantenendo alta l'efficienza, fino ad una luminosità integrata di 3000 $\mathrm{fb^{-1}}$. Inoltre per la parte esterna del tracciatore non si prevedono interventi di manutenzione, mentre per la parte di tracciatore a pixel sono sotto studio opzioni che consentano di operare sostituzioni nella zona più interna. 
\end{itemize}

\[
\begin{array}{lccc}

\toprule
\mathrm{Regione} & \mathrm{Fluenza \quad massima} [n_{eq}/cm^2] & r [mm] & z[mm]  \\

\midrule

\mathrm{IT \quad barrel \quad layer 1} & 2.3\times10^{16} & 28 & 0\\

\mathrm{IT\quad barrel\quad layer 2} & 5.0\times10^{15} & 69 & 0\\

\mathrm{IT\quad barrel\quad layer 4} & 1.5\times10^{15} & 156 & 89\\

\mathrm{IT\quad forward,\quad ring 1} & 1.0\times10^{16} & 51 & 252\\

\mathrm{IT\quad service\quad cylinder} & 9.6\times10^{14} & 170 & 260\\

\bottomrule
\end{array}
\]

\begin{itemize}
\item \textbf{Alta risoluzione e un migliore sistema di separazione delle tracce}: l'attuale tracciatore ha prestazioni peggiori nel tracciare jet di alta energia, a causa della sovrapposizione di più hit nel rivelatore a pixel. Al fine di sfruttare al meglio la maggiore statistica che ci sarà con HL-LHC, è necessario migliorare la capacità nel distinguere due tracce molto vicine. 
Allo stesso modo  per assicurare alta efficienza, nonostante un maggiore pile-up, è necessaria una maggiore densità di canali di lettura. Come riferimento si stima che la media di pile-up per ogni bunch crossing sarà di circa 140, a fronte dei 40 attuali.

\item \textbf{Riduzione di materiale}: un fattore importante che limita l'attuale risoluzione  è la quantità di materiale che le particelle attraversano. Questo è responsabile di perdita di energia e scattering multipli, i quali causano un peggioramento nelle prestazioni dei calorimetri e nella precisione di ricostruzione dell'evento.

\item \textbf{Sistema di riconoscimento delle tracce affidabile e veloce}: maggiore pile-up significa complicazioni nella ricostruzione delle tracce e tempi più lunghi. La velocità nella ricostruzione è essenziale per la funzionalità del trigger di alto livello (High -Level Trigger). 

\item \textbf{Compatibilità con il nuovo trigger L1}: La selezione degli eventi nella nuova fase ad alta luminosità è una sfida importante, non solo per l'alto numero di particele e quindi tracce, ma anche perché l'alto numero di pile-up rende inefficienti gli algoritmi di selezione degli eventi. Per questo motivo parte del processo di ricostruzione, che attualmente è svolto ad alto livello, sarà spostato in L1il cui rate massimo raggiungerà i 750 kHz.

\item \textbf{Estensione della regione di accettanza delle tracce}: altri benefici per CMS possono essere ottenuti ampliando la copertura della regione in avanti da parte del tracciatore e dei calorimetri.

 
\end{itemize}


\subsection{Tracciatore interno}
La parte interna del tracciatore sarà dotata di moduli a pixel. Come già evidenziato, nella fase ad alta luminosità il punto cruciale per la progettazione sarà la tolleranza alla radiazione di di sensori e elettronica di lettura, come anche la parte di gestione dei dati e l'aumento di frequenza di lavoro per il trigger. 
I candidati per i sensori che  rispettano le richieste su risoluzione, separazione delle tracce e occupazione sono sensori di silicio, di spessore 100-150 $\mu$m, con pixel di 25 $\times$ 100 $\mu m^2$ o 50 $\times$ 50 $\mu m^2$. 
Di conseguenza il chip di lettura dovrà avere celle di piccola dimensione con basse soglie. Lo sviluppo di questo nuovo chip è portato avanti dalla collaborazione RD53 che vede insieme ATLAS e CMS, il progetto prevede un chip con celle di dimensione 2500 $\mu m^2$  in tecnologia CMOS a 65 nm. 
Tale configurazione dovrebbe consentire una migliore resistenza al danneggiamento da radiazione.

\subsubsection{Sensori}
\begin{figure}
\centering
\includegraphics[scale=0.35]{Immagini/Sensors}
\caption{Schema di due celle adiacenti con dimensioni $\mathrm{25 \times 100 \mu m^2}$ (sinistra) e $\mathrm{50 \times 50\mu m^2}$ (destra). Gli impianti n+ sono riportati in verde, in blu le metallizzazioni, in rosso le aree di p-stop , i contatti in arancione e in viola i le piazzole per i bump bond.}
\label{Sensors}
\end{figure}
L'ambiente in cui saranno immersi i sensori nella fase di alta luminosità sarà estremo sia in termini di luminosità integrata che istantanea. 
I sensori saranno esposti ad una fluenza di  $2.3 \times 10^{16} \mathrm{n_{eq}/cm^2}$ negli strati più interni del tracciatore con una luminosità integrata di 3000$\mathrm{fb^{-1}}$. La dose equivalente è circa 12 MGy (1.2 Grad). 
Date queste condizioni si è preferito optare per sensori il più sottili possibile, dato che il vantaggio di raccogliere più carica con sensori più spessi viene annullato dal peggioramento delle prestazioni dovuto all'aumento di difetti nel silicio, a causa dell'alto irraggiamento. 
Lo spessore attivo del sensore, nel caso pixel planare sarà tra i 100 e 150 $\mu$m ( nella fase-0 e fase-1 lo spessore dei pixel era tra i 270  e i 285 $\mu$m). 
Il test di questi sensori insieme ai chip di lettura dimostrerà la fattibilità di utilizzo di questo tipo di sensore in ambienti con alti livelli di radiazione, o se saranno necessarie modifiche. 
Rispetto al tracciatore di CMS di fase-1 l'area dei pixel sarà ridotta di un fattore 6. Le due possibilità prese in considerazione sono $\mathrm{25 \times 100 \mu m^2}$ e  $\mathrm{50 \times 50 \mu m^2}$. 
Nel processo di valutazione dei vari progetti per i pixel particolare rilevanza hanno i seguenti punti:
\begin{itemize}
\item \textbf{Metodo di contro polarizzazione}Schema di polarizzazione dei sensori prima di unirli al chip. Tra le opzioni considerate ci sono l'utilizzo di punch through comuni per polarizzare più pixel contemporaneamente, resistenze in poli-silicio, o l'assenza completa di un metodo di polarizzazione. in assenza di una griglia per la polarizzazione il test dei sensori richiederebbe altre tecniche per aver accesso ai singoli pixel. 

\item \textbf{Isolamento del pixel} isolamento attraverso p-stop o p-spray. Per risparmiare spazio, gli impianti di p-stop sono in comune tra i pixel adiacenti, invece di averne uno per ogni singolo pixel.
\item \textbf{Metal overhangs}
\end{itemize}

CMS ha avviato numerose proposte di $\mathrm{R \& D}$ per sensori planari, al fine di studiare  tutte le possibili opzioni di progetto nei sensori sottili con piccolo pitch. I sensori sono valutati attraverso esperimenti di test beam, prima e dopo irraggiamento, al fine di testare la resistenza alla radiazione, la risoluzione spaziale, l'efficienza di raccolta carica, e non ultima l'efficienza di cella. 
Le proposte includono sia sensori con pixel di dimensione $\mathrm{25 \times 100 \mu m^2}$ che $\mathrm{50 \times 50\mu m^2}$ con vari design . Queste proposte includono sensori compatibili sia con chip di lettura PSI46dig, che con il prototipo di ROC RD53A. 
In figura \ref{Sensors} è mostrato l'aspetto di due celle adiacenti con pixel di dimensione $\mathrm{25 \times 100 \mu m^2}$ (sinistra) e $\mathrm{50 \times 50\mu m^2}$ (destra). Questi sensori sono compatibili con il prototipo RD53A.

\subsubsection{Chip}

\begin{figure}
\centering
\includegraphics[scale=0.4]{Immagini/ChipBlockDiagram}
\caption{Architettura del chip con bassi livelli di rumore analogico con un sistema di digitalizzazione del ToT a 4 bit. Nello schema sono riportate anche l'interfaccia di controllo, posta nella zona di EOC (End Of Column), l'interfaccia di lettura e il sistema di alimentazione che sfrutta un regolatore di tensione con shunt (Shunt-LDO).}
\label{ChipBlockDiagram}
\end{figure}

La parte cruciale nel sistema di lettura per il tracciatore interno è la progettazione di un chip di lettura dei pixel resistente alle radiazioni. Il diagramma a blocchi del chip è mostrato in figura \ref{ChipBlockDiagram}. 
La carica raccolta su ogni pixel è amplificata, formata e digitalizzata con una risoluzione di 4 bit a 40 MHz, sfruttando l'informazione di ToT (Time Over Threshold)\footnote{Il metodo di ToT consiste nel misurare il tempo durante il quale l'impulso analogico è sopra una certa soglia.}, che viene poi digitalizzata e utilizzata come misura di carica raccolta. 
I segnali vengono memorizzati durante i 12.5 $\mu$s di latenza del trigger\footnote{Si fa riferimento a latenze che si avranno con il trigger di fase II.} e memorizzati localmente in vettori all'interno della regione di pixel (che potrà essere 2 $\times$ 2 o 4 $\times$ 4). 
I dati riguardanti eventi con trigger sono raccolti da questa memoria e dopo un appropriato processo di compressione dati, svolto all'interno del chip, questi sono inviati all'esterno del chip tramite E-links (Electrical links) ad una velocità di 1.28 Gb/s. 
Sempre all'interno del rivelatore sono presenti i moduli di conversione, basati su chip LpGBT, che riversano i dati provenienti da un massimo di 7  E-links in una fibra ottica da 10 Gb/s per il trasporto verso il sistema di acquisizione dati (DAQ), all'esterno del rivelatore. 
I comandi, i dati di configurazione, i segnali di trigger e il clock sono spediti a 2.5 Gb/s verso i moduli di conversione per poi essere convertiti e inviati ai moduli tramite E-links a 160 Mb/s. 
Gli impulsi di calibrazione sono disponibili per tutti i pixel, grazie ad un esteso sistema a doppio impulso che può iniettare due differenti segnali di calibrazione con tempi e livelli programmabili. 
Inoltre è presente la possibilità di monitorare l'attività del chip tramite un 
Sono presenti anche sensori per il controllo della temperatura del chip distribuiti in più punti, in particolare sensori di temperatura sono integrati nella parte del chip che si occupa dell'alimentazione. Questo infatti è il punto con la più alta densità di potenza dissipata, che può variare significativamente in funzione delle configurazioni. 
%All power supply voltages (before and
%after the power regulator) and currents can be measured. In addition, a large number of ana-
%logue operation parameters can be monitored: bias currents for analogue front-ends, band gap
%references, calibration pulse voltages, PLL control voltage, etc. Dedicated features to monitor
%radiation degradation at both single transistor level and digital level (ring oscillators) are also
%included.
Un rapido elenco delle caratteristiche del chip di lettura sono riportate in tabella:

\[
\begin{array}{ll}

\toprule

\midrule

\mathrm{Technology} & \quad 65 \mathrm{nm \quad CMOS}\\

\mathrm{Chip \quad size} & \quad \mathrm{22 mm \times (16.4 mm + 2 mm)} \\

\mathrm{Pixel \quad size} & \quad \mathrm{50 \times 50 \mu m^2, 25 \times 100 \mu m^2)} \\

\mathrm{Number\quad of\quad pixels} & \quad \mathrm{144320} \\

\mathrm{Hit \quad rate} & \quad \mathrm{< 3 GHz/cm^2} \\

\mathrm{Charge \quad resolution} & \quad \mathrm{24 bit \quad ToT} \\


\bottomrule
\end{array}
\]

%si può allungare la lista

Le richieste tecniche per questo nuovo PROC (Pixel Read Out Chip) hanno portato ad l'utilizzo di moderna tecnologia CMOS a consumi ridotti ed alta densità con alimentazione a bassa tensione, circa 1.2 V. Questo fa si che il chip sia alimentato con correnti significative, circa 2.2 A per chip. 
La prima idea potrebbe essere quella di utilizzare convertitori DC-DC locali, ma questa possibilità è esclusa  a causa dell'ambiente ricco di radiazioni, del poco spazio disponibile e del tentativo di limitare il più possibile la quantità di materiale nel tracciatore. 

\begin{figure}
\centering
\includegraphics[scale=0.4]{Immagini/serial}
\caption{Sistema di alimentazione seriale dei moduli, ognuno dei quali ha al suo interno 4 o 2 chip in parallelo. Sul chip l'alimentazione è gestita da due SLDO in parallelo, uno per la parte digitale e uno per quella analogica.}
\label{serial}
\end{figure}

La soluzione scelta è dunque quella di utilizzare un sistema di alimentazione seriale, ciò permetto l'utilizzo di un quantitativo minimo di materiale e mantiene a livelli accettabili la perdita di potenza sui cavi. 
La catena è composta da 8-10 moduli ognuno con 2 o 4 chip connessi in parallelo, come si può vedere in figura \ref{serial}. 
All'interno del chip è incluso circuito ottimizzato per l'alimentazione che combina le capacità di uno shunt di corrente e di un regolatore LDO (Low DropOut), chiamato Shunt-LDO (SLDO). 
Come vedremo nel capitolo successivo lo SLDO assicura un consumo di corrente/potenza costante, indipendentemente dal rate di eventi e di trigger. 
Inoltre grazie ad una attenta progettazione è assicurata una suddivisione delle correnti appropriata tra i vari chip posti in parallelo all'interno del modulo. Lo stesso chip al suo interno ha due SLDO in parallelo uno per la parte analogica e uno per quella digitale. 
Questa separazione è resa necessaria per rendere minima l'influenza del rumore della parte digitale su la parte analogica, più sensibile  al rumore.